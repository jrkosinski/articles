{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3800cf3-7d7a-4a51-a37a-15b7e802a9fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 14:33:20.442226: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 14:33:20.578774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-27 14:33:20.578793: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-27 14:33:21.349910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-27 14:33:21.349985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-27 14:33:21.349993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import keras\n",
    "import math \n",
    "import random \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dedee0d-0373-4369-8dfd-05aae514adf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------\n",
    "# Encapsulates a single data point indicating a trend change. \n",
    "# \n",
    "class TrendPoint: \n",
    "    def __init__(self, index: int, price: float, point_type: str): \n",
    "        self.index = index\n",
    "        self.price = price\n",
    "        self.point_type = point_type\n",
    "    \n",
    "# -----------------------------------------------------------------\n",
    "# Encapsulates a metaseries indicating trend changes in a price \n",
    "# series. \n",
    "# \n",
    "class TrendData: \n",
    "    def __init__(self): \n",
    "        self.points = list()\n",
    "        \n",
    "    @property\n",
    "    def length(self): \n",
    "        return len(self.points)\n",
    "    \n",
    "    @property \n",
    "    def last_point(self): \n",
    "        if (self.length) < 1: \n",
    "            return None\n",
    "        return self.points[-1]\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # Appends a data point of a given type to the end of the metaseries.\n",
    "    # If a point of that type already exists at the end of the metaseries, \n",
    "    # it is replaced with the new point's data.\n",
    "    # \n",
    "    def append_point(self, index: int, price: float, ptype: str): \n",
    "        if (self.length > 0 and self.points[-1].point_type == ptype): \n",
    "            self.points[-1].index = index\n",
    "            self.points[-1].price = price\n",
    "        else:\n",
    "            self.points.append(TrendPoint(index, price, ptype))\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # Returns the metaseries normalized to be overlaid over the original\n",
    "    # price series.\n",
    "    # \n",
    "    def as_price_series(self, start_price: float): \n",
    "        series = list()\n",
    "        index = 0\n",
    "        price = start_price\n",
    "        \n",
    "        for i in range(self.length): \n",
    "            point = self.points[i]\n",
    "            price_diff = point.price - price\n",
    "            index_diff = point.index - index\n",
    "            if (index_diff > 1): \n",
    "                slope = price_diff / index_diff\n",
    "                \n",
    "                for n in range(index_diff): \n",
    "                    series.append(price + (n * slope))\n",
    "                    \n",
    "                price = point.price\n",
    "                index = point.index\n",
    "        \n",
    "        return series\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # Returns the metaseries normalized to the length of the original \n",
    "    # price series, with the following form: \n",
    "    #\n",
    "    # trend downturn (reversal to the down direction): 0 \n",
    "    # trend upturn (reversal to the up direction): 1\n",
    "    # continuation: 0.5\n",
    "    # \n",
    "    def as_boolean(self, start_price: float): \n",
    "        series = list()\n",
    "        prev_index = 0\n",
    "        prev_price = start_price\n",
    "        \n",
    "        for i in range(self.length): \n",
    "            point = self.points[i]\n",
    "            price_diff = point.price - prev_price\n",
    "            index_diff = point.index - prev_index\n",
    "                \n",
    "            if (index_diff > 1): \n",
    "                for n in range(1, index_diff): \n",
    "                    series.append(0.5)\n",
    "                    \n",
    "            if (price_diff < 0): \n",
    "                series.append(1)\n",
    "            else: \n",
    "                series.append(0)\n",
    "                    \n",
    "            prev_price = point.price\n",
    "            prev_index = point.index\n",
    "        \n",
    "        return series\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # Returns an x,y series containing either the highs (trend downturns)\n",
    "    # or the lows (trend upturns). \n",
    "    #\n",
    "    # Returns as tuple: x, y\n",
    "    # \n",
    "    def as_scatterplot(self, ptype: str):\n",
    "        x = list()\n",
    "        y = list()\n",
    "        \n",
    "        for i in range(self.length): \n",
    "            if (self.points[i].point_type == ptype): \n",
    "                y.append(self.points[i].price)\n",
    "                x.append(self.points[i].index)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    \n",
    "# -----------------------------------------------------------------\n",
    "# Extracts an approximation of the trend and trend changes over \n",
    "# time of the given price series. \n",
    "# \n",
    "# df: pandas DataFrame containing the price series column\n",
    "# col_name: the name of the price column in the given DataFrame\n",
    "# period: a lower value will result in more granular trend changes \n",
    "# \n",
    "def extract_trend(series: pd.Series, period: int): \n",
    "    values = series.values\n",
    "    data = TrendData()\n",
    "    last_hi_price = values[0]\n",
    "    last_lo_price = values[0]\n",
    "    \n",
    "    #get the first high and low of the range 0-period\n",
    "    first_hi = values[0]\n",
    "    first_hi_index = 0\n",
    "    first_lo = values[0]\n",
    "    first_lo_index = 0\n",
    "    for i in range(period): \n",
    "        if (values[i] > first_hi): \n",
    "            first_hi = values[i]\n",
    "            first_hi_index = i\n",
    "        if (values[i] < first_lo): \n",
    "            first_lo = values[i]\n",
    "            first_lo_index = i\n",
    "    \n",
    "    #append the first high & low in the right order\n",
    "    if (first_hi_index > first_lo_index): \n",
    "        data.append_point(first_lo_index, first_lo, 'lo')\n",
    "        data.append_point(first_hi_index, first_hi, 'hi')\n",
    "    else: \n",
    "        data.append_point(first_hi_index, first_hi, 'hi')\n",
    "        data.append_point(first_lo_index, first_lo, 'lo')\n",
    "        \n",
    "    #get the remaining trend points\n",
    "    start_index = period\n",
    "    end_index = 0\n",
    "    \n",
    "    while (start_index < len(values)-1): \n",
    "        last_point = data.last_point\n",
    "    \n",
    "        # count [period] points out from start\n",
    "        end_index = start_index + period\n",
    "        if (end_index > len(values)): \n",
    "            end_index = len(values)\n",
    "            \n",
    "        new_lo = start_index\n",
    "        new_hi = start_index\n",
    "        point_added = False\n",
    "        \n",
    "        # find highs & lows in the current series subset \n",
    "        for i in range(start_index, end_index): \n",
    "            val = values[i]\n",
    "            if (last_point.point_type == 'hi'): \n",
    "                if (val > last_point.price):\n",
    "                    data.append_point(i, val, 'hi')\n",
    "                    point_added = True\n",
    "                    break\n",
    "                if (val < values[new_lo]): \n",
    "                    new_lo = i\n",
    "            else:\n",
    "                if (val < last_point.price):\n",
    "                    data.append_point(i, val, 'lo')\n",
    "                    point_added = True\n",
    "                    break\n",
    "                if (val > values[new_hi]): \n",
    "                    new_hi = i\n",
    "        \n",
    "        if not point_added: \n",
    "            if (values[new_lo] < values[start_index]):\n",
    "                data.append_point(new_lo, values[new_lo], 'lo')\n",
    "\n",
    "            if (values[new_hi] > values[start_index]):\n",
    "                data.append_point(new_hi, values[new_hi], 'hi')\n",
    "        \n",
    "        start_index = data.last_point.index\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef7a9b9-5423-4638-8e29-0168aa2ff41a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Range</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.989125</td>\n",
       "      <td>0.353968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Range    Change\n",
       "0  1.000000  0.437608\n",
       "1  1.000000  0.057881\n",
       "2  1.000000  0.000000\n",
       "3  1.000000  0.000000\n",
       "4  0.989125  0.353968"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale_col_values(df, col_name, min_value=0, max_value=1): \n",
    "    values = df[col_name].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(min_value, max_value))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "    df[col_name] = scaled_values.transpose()[0]\n",
    "    return df\n",
    "\n",
    "def squash_col_outliers(df, col_name, min_quantile=0.01, max_quantile=0.99): \n",
    "    q_lo = df[col_name].quantile(min_quantile)\n",
    "    q_hi  = df[col_name].quantile(max_quantile)\n",
    "    \n",
    "    df.loc[df[col_name] >= q_hi, col_name] = q_hi\n",
    "    df.loc[df[col_name] <= q_lo, col_name] = q_lo\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(\"data/TSLA-d.csv\", index_col=0)\n",
    "df.pop(\"Volume\")\n",
    "df[\"Range\"] = (df[\"High\"] - df[\"Low\"]) / df[\"Open\"]\n",
    "df.pop(\"Open\")\n",
    "df.pop(\"High\")\n",
    "df.pop(\"Low\")\n",
    "df['Change'] = df[\"Adj Close\"].pct_change()\n",
    "df = df. tail(-1) \n",
    "df.pop(\"Close\")\n",
    "df = pd.DataFrame(df.values, columns=['Adj Close', 'Range', 'Change'])\n",
    "df = squash_col_outliers(df, 'Change')\n",
    "df = squash_col_outliers(df, \"Range\", min_quantile=0.0, max_quantile=0.97)\n",
    "df = scale_col_values(df, 'Change')\n",
    "df = scale_col_values(df, 'Range')\n",
    "\n",
    "trend = extract_trend(df['Adj Close'], 100)\n",
    "#df['Trend'] = trend.as_boolean(df['Adj Close'][0])\n",
    "df.pop(\"Adj Close\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce00098-c4d8-404a-8854-53dc8a434aab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VI: Shaping the Data for LSTM Input\n",
    "\n",
    "'''\n",
    "Finally, we have 3 columns (or features): Range, Change, and Trend. \n",
    "Let's pretend that Change is what we want the model to predict. \n",
    "\n",
    "The input for a keras LSTM requires a three dimensional array with the shape: \n",
    "(s, t, f) \n",
    "\n",
    "s = samples: the number of samples in the data set (i.e. the number of rows of data) \n",
    "t = timesteps: the number of timesteps to be input for each sample (also sometimes called the 'lag')\n",
    "f = features: the number of distinct features to be considered; in this case, 3 (Range, Change, Trend)\n",
    "\n",
    "An LSTM can predict multiple output features, and can do so with a variable offset and width. But just to \n",
    "keep things simple, we'll assume for this example that the output offset is 1, the LSTM will predict only \n",
    "one output feature (Change), and it will predict for only one timestep: the next day's Change. \n",
    "\n",
    "Note also that the output feature need not be one of the input features as well. In this case, Change is \n",
    "present in both the input and the output. \n",
    "\n",
    "X represents the input values. \n",
    "y represents the predicted or expected values. \n",
    "\n",
    "X: Range(t[-10:0]), Change(t[-10:0]), Trend(t[-10:0])\n",
    "y: Change (t+1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee65dc-2dad-408f-81da-2d299f750bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract y column (col to be predicted)\n",
    "def extract_y(df, colname, ntimesteps): \n",
    "    #TODO: don't need to shift here \n",
    "    shifted = df.shift(1)\n",
    "    shifted = shifted.tail(-1) \n",
    "    shifted = shifted.tail(-ntimesteps)\n",
    "    return shifted[colname].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8451dd64-9baf-44aa-845b-9fd7a140c351",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract X \n",
    "def extract_X(df, ntimesteps): \n",
    "    features = len(df.columns)\n",
    "    X = list()\n",
    "    \n",
    "    #offset for timesteps\n",
    "    offsets = list()\n",
    "    for i in range (ntimesteps, 0, -1): \n",
    "        offsets.append(df.shift(i))\n",
    "        \n",
    "    #combine timestep columns into rows \n",
    "    combined = pd.concat(offsets, axis=1)\n",
    "    combined = combined.tail(-ntimesteps) \n",
    "    combined.drop(combined.tail(1).index, inplace=True)\n",
    "    \n",
    "    #reshape each row (timesteps, features)\n",
    "    for i in range(len(combined)): \n",
    "        row = combined.iloc[i].to_numpy()\n",
    "        xrow = list()\n",
    "        for n in range(ntimesteps): \n",
    "            xrow.append(row[n*features:(n*features)+features])\n",
    "        X.append(xrow)\n",
    "    \n",
    "    #return as numpy array\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce2441b-b69e-4748-93a4-efbf4a19d573",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 10, 3)\n",
      "(3200,)\n"
     ]
    }
   ],
   "source": [
    "# EXTRACT X and y\n",
    "timesteps = 10\n",
    "X = extract_X(df, timesteps)\n",
    "y = extract_y(df, 'Change', timesteps)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0547708-0b15-4a82-93a1-a97180d29b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self, X, y): \n",
    "        if X.ndim != 3: \n",
    "            raise Exception(\"Expected a 3-dimensional array for X\")\n",
    "        if y.ndim != 1: \n",
    "            raise Exception(\"Expected a 1-dimensional array for y\")\n",
    "        if len(X) != len(y): \n",
    "            raise Exception(\"Length of X and y must be the same\")\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def split(self, pct): \n",
    "        count = int(self.size * pct)\n",
    "        new_dataset = DataSet(self.X[:count], self.y[:count])\n",
    "        self.X = self.X[:-count]\n",
    "        self.y = self.y[:-count]\n",
    "        return new_dataset\n",
    "        \n",
    "    @property\n",
    "    def size(self): \n",
    "        return len(self.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a06cfd-b0cb-4f66-9783-85c5c143f21d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SPLIT TO TEST & TRAIN\n",
    "train = DataSet(X, y)\n",
    "val = train.split(0.3)\n",
    "test = val.split(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5fe474-0b50-4243-b83e-35e84b37e5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain\u001b[49m\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(val\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(test\u001b[38;5;241m.\u001b[39msize)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "print(train.size)\n",
    "print(val.size)\n",
    "print(test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888d355-38f6-4ff9-af75-d4dad2e59dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b34236-8f98-4e24-a6df-87355a46c134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
